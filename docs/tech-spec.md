# Введение

В этом документе буду описывать все пояснения по реализации.
Логично, полезно разработчикам и инженерам поддержки.
Бизнесу тут делать нечего.

# Структуры данных

## Название очереди

Название очереди представляется структурой `QueueName`.
Само название должно удовлетворять бизнес-требованиям, указанным в [функциональной спецификации](func-spec.md#название-очереди)

В качестве кодировки используется `ASCII`.
Выбранные допустимые символы образуют непрерывный диапазон кодов из таблицы.
Начинается с 33 `!`, заканчивающиеся 126 `~`.

Поэтому проверка будет тривиальной - проверка диапазона байта символа

Первые 127 символов `ASCII` совпадают с первыми символами `UTF-8`, поэтому в случае правильного назваания, кодировки можно использовать взаимозаменяемо.

Так как максимальная длина названия 255 символов соответствует максимальному значению байта и каждый символ занимает 1 байт, 
то длина строки названия указывается байтом (беззнаковым).

# Файловая система

## Базовая директория

Базовая директория наследуется от вызывающей программы. 
Поэтому, `TaskFlux` надо запускать из директории, в которой находятся нужные файлы для выполнения.

> TODO: может надо добавить возможность указывать базовую/рабочую директорию при запуске

## Файловая структура

В базовой директории должны находиться все указанные файлы и каталоги для корректной работы приложения.
`*Base*` указывает на базовую директорию.

`*Base*`:

- `consensus` - директория, содержащая файлы необходимые для рафта
    - `raft.log` - файл с логом реплицируемых команд
    - `raft.metadata` - файл с метаданными узла (метаданные, необходимые для рафта)
    - `raft.snapshot` - файл слепка состояния системы для восстановления после старта

Каждый файл, относящийся к приложению, имеет специальный префикс.
Если этот префикс отсутствует или неправильный, то приложение должно упасть с ошибкой, в сообщении которой будет указана
эта причина.

### `consensus/raft.log`

Файл представляет лог команд для рафта.

Структура файла:

| Маркер  | Версия | Терм  | Данные       |
|---------|--------|-------|--------------|
| Byte(4) | Int32  | Int32 | Array\<Byte> |

Поля:

- `Маркер` - специальный маркер
- `Версия` - версия формата файла (текущая версия 1)
- `Терм` - терм, в которой команда была применена
- `Данные` - сериализованная данные команды для машины состояний

Поля `Терм` и `Данные` образуют логическую единицу - команду (в соответствии с алгоритмом рафта).
Они повторяются до конца файла.
Никаких маркеров начала/конца команды нет.

Максимальный размер файла - 16 Мб

> Замечание: если сделаю фиксированный размер файла лога, то надо добавить маркеры начала/конца,
> иначе буду читать мусор

### `consensus/raft.metadata`

В этом файле содержатся общие метаданные, необходимые для корректной работы алгоритма.

Структура файла:

| Маркер  | Версия | Терм  | Голос |
|---------|--------|-------|-------|
| Byte(4) | Int32  | Int32 | Int32 |

Поля:

- `Маркер` - специальный маркер файла
- `Версия` - версия файла
- `Терм` - последний сохраненный терм
- `Голос` - значение ID узла, за который голосовали последний раз.
  0 означает отсутствие голоса. Отрицательные значения не допускаются.

### `consensus/raft.snapshot`

В этом файле хранится слепок состояния приложения.

Структура файла:

| Маркер | Последний индекс | Последний терм | Состояние         |
|--------|------------------|----------------|-------------------|
| Marker | Int32            | Int32          | Array\<QueueData> |

Поле состояние состоит из идущих друг за другом структур `QueueData`.
Формат представлен ниже:

| Название очереди | Максимальный размер | Размер очереди | Очередь                      |
|------------------|---------------------|----------------|------------------------------|
| QueueName        | UInt32              | UInt32         | Pair\<Int64, Array\<byte>>[] |

Поле `Очередь` содержит повторяющиеся сериализованные значения всех элементов очереди - пара приоритет-нагрузка.
Количество элементов определяется полем `Размер очереди`.

> Замечание: данные в очереди необязательно должны быть в правильной очередности,
> очередь восстанавливается во время старта из этих значений. 

# Узел

TaskFlux работает в кластере из нескольких узлов.
Каждый узел идентифицируется собственным Id.

Id представляется целым числом, начинающимся с 0 и линейно увеличивающимся.
Т.е. Id узлов в кластере начинаются с 0 и каждый другой узел имеет Id на 1 больший, чем предыдущий.
Например: 0, 1, 2, 3 или 0, 1.
Такая стратегия удобная в случае использования в коде.

Максимальное значение Id узла - 2147483647.
Представляется 4 байтным знаковым целым.
Этого более чем достаточно для реальных сред.

# Установление соединения

Клиент работает с кластером напрямую (на данный момент, клиентские запросы не перенаправляются на лидера).

## Установление соединение клиента и узла

Когда клиент присоединился к узлу, то между ними начинается процесс настройки соединения.
Это нужно для авторизации клиента и выставления общих настроек клиента и сервера.

Процесс установления соединения.

1. Клиент устанавливает соединение с узлом
2. Клиент посылает AuthorizationRequest пакет
3. Сервер авторизует клиента по переданным данным
4. Клиент получает AuthorizationResponse пакет с результатом авторизации
    1. Если авторизация завершилась ошибкой, то сервер закрывает соединение
    2. Дальнейшая работа прекращается
5. Клиент отправляет BootstrapRequest пакет
6. Сервер выставляет нужные настройки и проверяет корректность клиента
7. Клиент получает BootstrapResponse пакет
    1. Если проверка провалилась, то сервер закрывает соединение
    2. Дальнейшая работа прекращается

После указанного процесса, узел может обрабатывать запросы клиента.

Замечания:

- На данный момент авторизация не реализована - простой обмен предопределенными пакетами
- Сейчас на этапе первоначальной настройки реализована только проверка версии, никаких настроек нет.

## Получение метаданных кластера

Для гибкости работы, вместо ручного заполнения адресов и Id узлов, клиент может сам запросить данные о кластере для
дальнейшей работы с ним.

Чтобы получить метаданные кластера (узлы, Id лидера), клиент должен запросить их у любого узла с помощью
ClusterMetadataRequest пакета.
Список таких узлов передается на вход клиентской библиотеке при старте.
Далее это "Bootstrap" серверы.

После клиент поочередно перебирает этот список в попытке подключения и получения метаданных.

Для каждого Bootstrap узла из переданного списка выполняется следующая процедура для получения метаданных кластера:

1. Выполняется [настройка соединения](#установление-соединение-клиента-и-узла) с узлом
    1. Если соединиться с узлом не удалось из-за сети, то переходим к следующему адресу
    2. Если в процессе установления соединения возникла ошибка (ошибка авторизации или первоначальной настройки), то
       дальнейшая работа прекращается
2. Клиент отправляет ClusterMetadataRequest пакет
3. Сервер отправляет метаданные кластера в ClusterMetadataResponse пакете
4. Клиент сохраняет метаданные кластера
5. Если узел, с которым производилась коммуникация:
    1. Лидер: работа продолжается с этим узлом
    2. Не лидер: соединение с этим узлом закрывается, производится подключение к лидеру (если не был указан, то к
       случайному)

На этапе 1.2 дальнейшая работа прекращается, так как если авторизация/настройка провалилась на одном узле, то она
провалится и на остальных.

Замечание: если на момент запроса узел-лидер не был указан, то процесс повторяется для случайного узла из списка
полученных узлов (возможно даже со старым узлом, так как за это время он мог стать лидером).

Замечание: в пакете ClusterMetadataResponse может указываться Id текущего узла.
Пока не выставляю требований на его проверку, считаю, что всегда говорить будет с узлом кластера,
но в будущем можем сделать отдельный сервер, хранящий метаданные кластера, тогда это поле будет иметь специальное
значение.

Процесс инициализации считается успешным, если метаданные были получены.

## Ручная настройка

Если у нас уже имеется готовый список адресов узлов и их Id, процесс установления соединения и получения метаданных
будет лишним.
В этом случае, клиент уже должен знать список всех узлов кластера и их адресов.

## Метаданные кластера

Метаданные кластера передаются в пакете ClusterMetadataResponse.
Они включают в себя:

- Список адресов узлов кластера
- Id текущего лидера кластера
- Id ответившего узла

Список адресов передается в виде массива строк. Каждая строка может быть либо IP адресом, либо DNS записью (оба вместе с
портами).
Т.е. явного разделения между ними нет.

Замечание: предполагаю, что чаще будут использовать именно DNS записи, чем IP адреса

Id узлов аналогичны индексам в этом массиве:

| Индекс | Id | Адрес                |
|--------|----|----------------------|
| 0      | 0  | task-flux-0.ru:2602  |
| 1      | 1  | task-flux-1.aws.com  |
| 2      | 2  | server.org:5432      |
| 3      | 3  | 123.123.123.123:6666 |

Id узла лидера может быть не указан. Это может быть в случаях:

- Кластер только что был запущен и лидера не было изначально
- Узел, к которому подключились, был отрезан от остальных
- Узел с более актуальными данными поднялся и начался процесс выбора

В любом случае, рано или поздно лидер будет выбран, поэтому можно просто случайно подключаться к узлам и получать их
статус.
